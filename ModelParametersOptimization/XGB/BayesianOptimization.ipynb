{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/tilii7/bayesian-optimization-of-xgboost-parameters\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "timestr = time.strftime(\"%Y%m%d-%H%M%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init_points=2\n",
    "n_iter=5\n",
    "acq='ei'\n",
    "xi=1e-4\n",
    "folds = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#log_file\n",
    "log_file = open('/home/kate/logs/BaysianOptimization/full_log_%s.log'%acq,  'w')\n",
    "log_file_bestparam = open('/home/kate/logs/BaysianOptimization/bestparam_%s.log'%acq,  'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "#log in csv file\n",
    "csv_file='/home/kate/logs/BestModel_%s.log.csv'%acq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#data\n",
    "dataset = pd.read_csv('/home/kate/data/ClaimPrediction/fdata_v1_encd.csv', index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#features\n",
    "target_column = 'hasclaim'\n",
    "featureset=[\n",
    "'accidentpreventioncourseind_encd',\n",
    "'carpoolind_encd',\n",
    "'classcd_encd',\n",
    "'driverage',\n",
    "'drivernumber',\n",
    "'driverstatuscd_encd',\n",
    "'drivertrainingind_encd',\n",
    "'estimatedannualdistance',\n",
    "'gooddriverind_encd',\n",
    "'maturedriverind_encd',\n",
    "'mvrstatus_encd',\n",
    "'mvrstatusage',\n",
    "'ratingvalue',\n",
    "'relationshiptoinsuredcd_encd',\n",
    "'scholasticdiscountind_encd',\n",
    "'vehbodytypecd_encd',\n",
    "'vehicleage',\n",
    "'vehnumber'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#xgb library and parameters to tune later\n",
    "import xgboost as xgb\n",
    "xgb_params = {'eta': 0.02, 'max_depth': 4, 'subsample': 0.9, 'colsample_bytree': 0.9, \n",
    "          'objective': 'binary:logistic', 'eval_metric': 'auc', 'silent': True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Random Undersampler to balance the dataset\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "rus = RandomUnderSampler(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting to train/test\n",
    "from sklearn.model_selection import train_test_split\n",
    "s=0.25\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset.loc[:,featureset], dataset[target_column], test_size=s, random_state=42)\n",
    "X_train = X_train.values\n",
    "y_train = y_train.values\n",
    "#balancing dataset\n",
    "X_res, y_res = rus.fit_sample(X_train, y_train)\n",
    "dtrain = xgb.DMatrix(X_res, y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#best metric variables\n",
    "AUCbest = -1.\n",
    "ITERbest = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv fold for each parameters set\n",
    "def xgb_evaluate(max_depth,\n",
    "                 min_child_weight,\n",
    "                 colsample_bytree,\n",
    "                 subsample,\n",
    "                 gamma,\n",
    "                 colsample_bylevel,\n",
    "                 max_delta_step,\n",
    "                 eta,\n",
    "                 reg_alpha,\n",
    "                 reg_lambda\n",
    "         ):\n",
    "\n",
    "    global AUCbest\n",
    "    global ITERbest\n",
    "\n",
    "    params={}\n",
    "    params['booster'] = 'gbtree'\n",
    "    params['min_child_weight'] = int(min_child_weight)\n",
    "    params['cosample_bytree'] = max(min(colsample_bytree, 1), 0)\n",
    "    params['max_depth'] = int(max_depth)\n",
    "    params['subsample'] = max(min(subsample, 1), 0)\n",
    "    params['gamma'] = gamma\n",
    "    params['colsample_bylevel'] = max(min(colsample_bylevel, 1), 0)\n",
    "    params['max_delta_step']=max(int(max_delta_step),0)\n",
    "    params['eta']=max(min(eta,1), 0)\n",
    "    params['reg_alpha'] = max(reg_alpha, 0)\n",
    "    params['reg_lambda']=max(min(reg_lambda, 1), 0)\n",
    "    params['eval_metric']='auc'\n",
    "    params['silent']=True\n",
    "    params['objective']='binary:logistic'\n",
    "    params['seed'] =42\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    print(\"\\n Search parameters (%d-fold validation):\\n %s\" % (folds, params), file=log_file )\n",
    "    log_file.flush()\n",
    "\n",
    "    xgbc = xgb.cv(\n",
    "                    params,\n",
    "                    dtrain,\n",
    "                    num_boost_round = 20000,\n",
    "                    stratified = True,\n",
    "                    nfold = folds,\n",
    "                    early_stopping_rounds = 100,\n",
    "                    metrics = 'auc',\n",
    "                    show_stdv = True\n",
    "               )\n",
    "\n",
    "\n",
    "    val_score = xgbc['test-auc-mean'].iloc[-1]\n",
    "    train_score = xgbc['train-auc-mean'].iloc[-1]\n",
    "    print(' Stopped after %d iterations with train-auc = %f val-auc = %f ( diff = %f ) train-gini = %f val-gini = %f' \n",
    "          % ( len(xgbc), train_score, val_score, (train_score - val_score), (train_score*2-1),\n",
    "(val_score*2-1)) , file=log_file)\n",
    "    if ( val_score > AUCbest ):\n",
    "        AUCbest = val_score\n",
    "        ITERbest = len(xgbc)\n",
    "        print('\\n\\nBest Valid AUC changed to %f'%AUCbest, file=log_file)\n",
    "        log_file.flush()\n",
    "        #\n",
    "        print(\"\\n Best parameters (%d-fold validation):\\n %s\" % (folds, params), file=log_file_bestparam )\n",
    "        print('\\n Best Valid AUC changed to %f'%AUCbest, file=log_file_bestparam)\n",
    "        print('\\n Train AUC is %f'%train_score, file=log_file_bestparam)\n",
    "        log_file_bestparam.flush()\n",
    "        #\n",
    "    return (val_score*2) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#bayesian optimization\n",
    "from bayes_opt import BayesianOptimization\n",
    "XGB_BO = BayesianOptimization(xgb_evaluate, {   'max_depth': (2, 12),\n",
    "                                                'min_child_weight': (0.1, 20),\n",
    "                                                'colsample_bytree': (0.2, 1.1),\n",
    "                                                'subsample': (0.1, 1.1),\n",
    "                                                'gamma': (0.001, 10),\n",
    "                                                'colsample_bylevel': (0.2, 1.1),\n",
    "                                                'max_delta_step':(0,10),\n",
    "                                                'eta':(0.01,1.1),\n",
    "                                                'reg_alpha': (0, 10),\n",
    "                                                'reg_lambda':(1,10)\n",
    "                                                })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   colsample_bylevel |   colsample_bytree |       eta |     gamma |   max_delta_step |   max_depth |   min_child_weight |   reg_alpha |   reg_lambda |   subsample | \n",
      "    1 | 00m10s | \u001b[35m   0.37405\u001b[0m | \u001b[32m             1.0210\u001b[0m | \u001b[32m            1.0346\u001b[0m | \u001b[32m   0.0149\u001b[0m | \u001b[32m   2.6369\u001b[0m | \u001b[32m          8.8963\u001b[0m | \u001b[32m     4.7117\u001b[0m | \u001b[32m           15.5839\u001b[0m | \u001b[32m     7.8881\u001b[0m | \u001b[32m      5.6246\u001b[0m | \u001b[32m     0.1635\u001b[0m | \n",
      "    2 | 00m01s |    0.35730 |              1.0485 |             0.3696 |    0.4980 |    3.5478 |           0.5715 |     10.8642 |            18.8045 |      4.4984 |       8.1266 |      0.5987 | \n",
      "\u001b[31mBayesian Optimization\u001b[0m\n",
      "\u001b[94m-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   colsample_bylevel |   colsample_bytree |       eta |     gamma |   max_delta_step |   max_depth |   min_child_weight |   reg_alpha |   reg_lambda |   subsample | \n",
      "    3 | 00m29s |    0.22810 |              0.2000 |             1.1000 |    0.0100 |   10.0000 |          10.0000 |      2.0000 |             0.1000 |     10.0000 |       1.0000 |      0.1000 | \n",
      "    4 | 00m37s |    0.35139 |              1.1000 |             1.1000 |    0.0100 |    0.0010 |          10.0000 |      2.0000 |            20.0000 |      0.0000 |      10.0000 |      0.1000 | \n",
      "    5 | 00m49s |    0.35120 |              1.1000 |             1.1000 |    0.0100 |    0.0010 |          10.0000 |     12.0000 |            20.0000 |     10.0000 |       1.0000 |      0.1000 | \n",
      "    6 | 00m47s | \u001b[35m   0.38387\u001b[0m | \u001b[32m             1.1000\u001b[0m | \u001b[32m            0.2000\u001b[0m | \u001b[32m   0.0100\u001b[0m | \u001b[32m   0.0010\u001b[0m | \u001b[32m          0.0000\u001b[0m | \u001b[32m     2.0000\u001b[0m | \u001b[32m           20.0000\u001b[0m | \u001b[32m    10.0000\u001b[0m | \u001b[32m     10.0000\u001b[0m | \u001b[32m     1.1000\u001b[0m | \n",
      "    7 | 00m44s |    0.27380 |              1.1000 |             1.1000 |    1.1000 |   10.0000 |          10.0000 |      4.9719 |            20.0000 |     10.0000 |      10.0000 |      0.1000 | \n"
     ]
    }
   ],
   "source": [
    "#run optimization\n",
    "print('-'*130)\n",
    "print('-'*130, file=log_file)\n",
    "log_file.flush()\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings('ignore')\n",
    "    XGB_BO.maximize(init_points=init_points, n_iter=n_iter, acq=acq, xi=xi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "Final Results\n",
      "Maximum XGBOOST value: 0.383866\n",
      "Best XGBOOST parameters:  {'max_depth': 2.0, 'min_child_weight': 20.0, 'colsample_bytree': 0.20000000000000001, 'subsample': 1.1000000000000001, 'gamma': 0.001, 'colsample_bylevel': 1.1000000000000001, 'max_delta_step': 0.0, 'eta': 0.01, 'reg_alpha': 10.0, 'reg_lambda': 10.0}\n"
     ]
    }
   ],
   "source": [
    "print('-'*130)\n",
    "print('Final Results')\n",
    "print('Maximum XGBOOST value: %f' % XGB_BO.res['max']['max_val'])\n",
    "print('Best XGBOOST parameters: ', XGB_BO.res['max']['max_params'])\n",
    "print('-'*130, file=log_file)\n",
    "print('Final Result:', file=log_file)\n",
    "print('Maximum XGBOOST value: %f' % XGB_BO.res['max']['max_val'], file=log_file)\n",
    "print('Best XGBOOST parameters: ', XGB_BO.res['max']['max_params'], file=log_file)\n",
    "log_file.flush()\n",
    "log_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "history_df = pd.DataFrame(XGB_BO.res['all']['params'])\n",
    "history_df2 = pd.DataFrame(XGB_BO.res['all']['values'])\n",
    "history_df = pd.concat((history_df, history_df2), axis=1)\n",
    "history_df.rename(columns = { 0 : 'gini'}, inplace=True)\n",
    "history_df['AUC'] = ( history_df['gini'] + 1 ) / 2\n",
    "history_df.to_csv(csv_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
